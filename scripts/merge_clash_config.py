#!/usr/bin/env python3
"""
Clashé…ç½®æ–‡ä»¶æ•´åˆå·¥å…·
ä»GitHubç§æœ‰ä»“åº“è¯»å–å¤šä¸ªè®¢é˜…YAMLæ–‡ä»¶ï¼Œæ•´åˆä»£ç†èŠ‚ç‚¹å’Œè§„åˆ™ï¼Œç”Ÿæˆç»Ÿä¸€çš„Clashé…ç½®
"""

import os
import sys
import yaml
import requests
import base64
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ClashConfigMerger:
    def __init__(self, github_token: str, repo_owner: str, repo_name: str):
        """
        åˆå§‹åŒ–Clashé…ç½®åˆå¹¶å™¨
        
        Args:
            github_token: GitHubè®¿é—®ä»¤ç‰Œ
            repo_owner: ä»“åº“æ‰€æœ‰è€…
            repo_name: ä»“åº“åç§°
        """
        self.github_token = github_token
        self.repo_owner = repo_owner
        self.repo_name = repo_name
        self.headers = {
            'Authorization': f'token {github_token}',
            'Accept': 'application/vnd.github.v3+json'
        }
        self.base_url = f'https://api.github.com/repos/{repo_owner}/{repo_name}/contents'
        
    def get_file_content(self, file_path: str) -> Optional[str]:
        """
        ä»GitHubä»“åº“è·å–æ–‡ä»¶å†…å®¹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            url = f'{self.base_url}/{file_path}'
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            file_data = response.json()
            if file_data['encoding'] == 'base64':
                content = base64.b64decode(file_data['content']).decode('utf-8')
                logger.info(f"æˆåŠŸè·å–æ–‡ä»¶: {file_path}")
                return content
            else:
                logger.error(f"ä¸æ”¯æŒçš„ç¼–ç æ ¼å¼: {file_data['encoding']}")
                return None
                
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
        except Exception as e:
            logger.error(f"è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None
    
    def load_yaml_content(self, content: str) -> Optional[Dict[str, Any]]:
        """
        è§£æYAMLå†…å®¹
        
        Args:
            content: YAMLå­—ç¬¦ä¸²å†…å®¹
            
        Returns:
            è§£æåçš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            return yaml.safe_load(content)
        except yaml.YAMLError as e:
            logger.error(f"YAMLè§£æå¤±è´¥: {e}")
            return None
    
    def get_directory_files(self, directory_path: str) -> List[str]:
        """
        è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            url = f'{self.base_url}/{directory_path}'
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            
            files = response.json()
            file_paths = []
            
            for file_info in files:
                if file_info['type'] == 'file' and file_info['name'].endswith('.yaml'):
                    file_paths.append(file_info['path'])
                    
            logger.info(f"å‘ç° {len(file_paths)} ä¸ªYAMLæ–‡ä»¶åœ¨ç›®å½•: {directory_path}")
            return file_paths
            
        except requests.exceptions.RequestException as e:
            logger.error(f"è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨å¤±è´¥ {directory_path}: {e}")
            return []
    
    def merge_proxies(self, configs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶å¤šä¸ªé…ç½®æ–‡ä»¶çš„ä»£ç†èŠ‚ç‚¹
        
        Args:
            configs: é…ç½®æ–‡ä»¶åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„ä»£ç†èŠ‚ç‚¹åˆ—è¡¨
        """
        merged_proxies = []
        seen_names = set()
        
        for config in configs:
            if 'proxies' in config and isinstance(config['proxies'], list):
                for proxy in config['proxies']:
                    if isinstance(proxy, dict) and 'name' in proxy:
                        # é¿å…é‡å¤çš„ä»£ç†èŠ‚ç‚¹åç§°
                        original_name = proxy['name']
                        name = original_name
                        counter = 1
                        
                        while name in seen_names:
                            name = f"{original_name}_{counter}"
                            counter += 1
                        
                        proxy['name'] = name
                        seen_names.add(name)
                        merged_proxies.append(proxy)
        
        logger.info(f"åˆå¹¶äº† {len(merged_proxies)} ä¸ªä»£ç†èŠ‚ç‚¹")
        return merged_proxies
    
    def merge_rules(self, configs: List[Dict[str, Any]], rule_files: List[str]) -> List[str]:
        """
        åˆå¹¶è§„åˆ™åˆ—è¡¨
        
        Args:
            configs: é…ç½®æ–‡ä»¶åˆ—è¡¨
            rule_files: è§„åˆ™æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            åˆå¹¶åçš„è§„åˆ™åˆ—è¡¨
        """
        merged_rules = []
        seen_rules = set()
        
        # ä»è§„åˆ™æ–‡ä»¶ä¸­åŠ è½½è§„åˆ™
        for rule_file_path in rule_files:
            content = self.get_file_content(rule_file_path)
            if content:
                rule_data = self.load_yaml_content(content)
                if rule_data and 'payload' in rule_data:
                    for rule in rule_data['payload']:
                        if isinstance(rule, str) and rule not in seen_rules:
                            # å°†è§„åˆ™æ ¼å¼åŒ–ä¸ºClashæ ¼å¼
                            if not rule.endswith(',PROXY') and not rule.endswith(',DIRECT'):
                                rule = f"{rule},PROXY"
                            merged_rules.append(rule)
                            seen_rules.add(rule)
        
        # ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½è§„åˆ™
        for config in configs:
            if 'rules' in config and isinstance(config['rules'], list):
                for rule in config['rules']:
                    if isinstance(rule, str) and rule not in seen_rules:
                        merged_rules.append(rule)
                        seen_rules.add(rule)
        
        logger.info(f"åˆå¹¶äº† {len(merged_rules)} æ¡è§„åˆ™")
        return merged_rules
    
    def create_proxy_groups(self, proxies: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆ›å»ºä»£ç†ç»„
        
        Args:
            proxies: ä»£ç†èŠ‚ç‚¹åˆ—è¡¨
            
        Returns:
            ä»£ç†ç»„é…ç½®åˆ—è¡¨
        """
        proxy_names = [proxy['name'] for proxy in proxies if 'name' in proxy]
        
        proxy_groups = [
            {
                'name': 'PROXY',
                'type': 'select',
                'proxies': ['è‡ªåŠ¨é€‰æ‹©', 'æ•…éšœè½¬ç§»'] + proxy_names
            },
            {
                'name': 'è‡ªåŠ¨é€‰æ‹©',
                'type': 'url-test',
                'proxies': proxy_names,
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300
            },
            {
                'name': 'æ•…éšœè½¬ç§»',
                'type': 'fallback',
                'proxies': proxy_names,
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300
            }
        ]
        
        # æŒ‰åœ°åŒºåˆ†ç»„
        regions = {}
        for proxy in proxies:
            name = proxy.get('name', '')
            if 'ğŸ‡­ğŸ‡°' in name or 'é¦™æ¸¯' in name:
                regions.setdefault('é¦™æ¸¯', []).append(name)
            elif 'ğŸ‡¨ğŸ‡³' in name or 'å°æ¹¾' in name:
                regions.setdefault('å°æ¹¾', []).append(name)
            elif 'ğŸ‡¸ğŸ‡¬' in name or 'æ–°åŠ å¡' in name:
                regions.setdefault('æ–°åŠ å¡', []).append(name)
            elif 'ğŸ‡¯ğŸ‡µ' in name or 'æ—¥æœ¬' in name:
                regions.setdefault('æ—¥æœ¬', []).append(name)
            elif 'ğŸ‡ºğŸ‡¸' in name or 'ç¾å›½' in name:
                regions.setdefault('ç¾å›½', []).append(name)
        
        # ä¸ºæ¯ä¸ªåœ°åŒºåˆ›å»ºä»£ç†ç»„
        for region, region_proxies in regions.items():
            if region_proxies:
                proxy_groups.append({
                    'name': f'{region}èŠ‚ç‚¹',
                    'type': 'select',
                    'proxies': region_proxies
                })
        
        logger.info(f"åˆ›å»ºäº† {len(proxy_groups)} ä¸ªä»£ç†ç»„")
        return proxy_groups

    def create_base_config(self) -> Dict[str, Any]:
        """
        åˆ›å»ºåŸºç¡€é…ç½®

        Returns:
            åŸºç¡€é…ç½®å­—å…¸
        """
        return {
            'mixed-port': 7890,
            'allow-lan': True,
            'bind-address': '*',
            'mode': 'rule',
            'log-level': 'info',
            'external-controller': '127.0.0.1:9090',
            'dns': {
                'enable': True,
                'ipv6': False,
                'default-nameserver': ['223.5.5.5', '119.29.29.29', '114.114.114.114'],
                'enhanced-mode': 'fake-ip',
                'fake-ip-range': '198.18.0.1/16',
                'use-hosts': True,
                'nameserver': ['223.5.5.5', '119.29.29.29', '114.114.114.114'],
                'fallback': ['1.1.1.1', '8.8.8.8'],
                'fallback-filter': {
                    'geoip': True,
                    'geoip-code': 'CN',
                    'ipcidr': ['240.0.0.0/4']
                }
            }
        }

    def generate_merged_config(self, sub_directory: str = 'sub', rule_directory: str = 'rule') -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆå¹¶åçš„é…ç½®æ–‡ä»¶

        Args:
            sub_directory: è®¢é˜…æ–‡ä»¶ç›®å½•
            rule_directory: è§„åˆ™æ–‡ä»¶ç›®å½•

        Returns:
            åˆå¹¶åçš„å®Œæ•´é…ç½®
        """
        logger.info("å¼€å§‹ç”Ÿæˆåˆå¹¶é…ç½®...")

        # è·å–è®¢é˜…æ–‡ä»¶åˆ—è¡¨
        sub_files = self.get_directory_files(sub_directory)
        if not sub_files:
            logger.warning(f"æœªæ‰¾åˆ°è®¢é˜…æ–‡ä»¶åœ¨ç›®å½•: {sub_directory}")

        # è·å–è§„åˆ™æ–‡ä»¶åˆ—è¡¨
        rule_files = self.get_directory_files(rule_directory)
        if not rule_files:
            logger.warning(f"æœªæ‰¾åˆ°è§„åˆ™æ–‡ä»¶åœ¨ç›®å½•: {rule_directory}")

        # åŠ è½½æ‰€æœ‰è®¢é˜…é…ç½®
        configs = []
        for file_path in sub_files:
            content = self.get_file_content(file_path)
            if content:
                config = self.load_yaml_content(content)
                if config:
                    configs.append(config)

        if not configs:
            logger.error("æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆçš„è®¢é˜…é…ç½®æ–‡ä»¶")
            return {}

        # åˆ›å»ºåŸºç¡€é…ç½®
        merged_config = self.create_base_config()

        # åˆå¹¶ä»£ç†èŠ‚ç‚¹
        merged_proxies = self.merge_proxies(configs)
        merged_config['proxies'] = merged_proxies

        # åˆ›å»ºä»£ç†ç»„
        proxy_groups = self.create_proxy_groups(merged_proxies)
        merged_config['proxy-groups'] = proxy_groups

        # åˆå¹¶è§„åˆ™
        merged_rules = self.merge_rules(configs, rule_files)

        # æ·»åŠ é»˜è®¤è§„åˆ™
        default_rules = [
            'DOMAIN-SUFFIX,local,DIRECT',
            'IP-CIDR,127.0.0.0/8,DIRECT',
            'IP-CIDR,172.16.0.0/12,DIRECT',
            'IP-CIDR,192.168.0.0/16,DIRECT',
            'IP-CIDR,10.0.0.0/8,DIRECT',
            'IP-CIDR,17.0.0.0/8,DIRECT',
            'IP-CIDR,100.64.0.0/10,DIRECT',
            'GEOIP,CN,DIRECT',
            'MATCH,PROXY'
        ]

        merged_config['rules'] = merged_rules + default_rules

        logger.info("é…ç½®åˆå¹¶å®Œæˆ")
        return merged_config

    def save_config_to_file(self, config: Dict[str, Any], output_path: str) -> bool:
        """
        ä¿å­˜é…ç½®åˆ°æ–‡ä»¶

        Args:
            config: é…ç½®å­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, default_flow_style=False, allow_unicode=True, sort_keys=False)

            logger.info(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    github_token = os.getenv('GITHUB_TOKEN')
    repo_owner = os.getenv('REPO_OWNER', 'your-username')
    repo_name = os.getenv('REPO_NAME', 'clash-config')
    output_dir = os.getenv('OUTPUT_DIR', 'docs')

    if not github_token:
        logger.error("æœªè®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡")
        sys.exit(1)

    # åˆ›å»ºåˆå¹¶å™¨å®ä¾‹
    merger = ClashConfigMerger(github_token, repo_owner, repo_name)

    # ç”Ÿæˆåˆå¹¶é…ç½®
    merged_config = merger.generate_merged_config()

    if not merged_config:
        logger.error("ç”Ÿæˆé…ç½®å¤±è´¥")
        sys.exit(1)

    # ä¿å­˜é…ç½®æ–‡ä»¶
    output_path = os.path.join(output_dir, 'clash.yaml')
    if not merger.save_config_to_file(merged_config, output_path):
        sys.exit(1)

    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    stats = {
        'generated_at': datetime.now().isoformat(),
        'proxy_count': len(merged_config.get('proxies', [])),
        'proxy_group_count': len(merged_config.get('proxy-groups', [])),
        'rule_count': len(merged_config.get('rules', []))
    }

    stats_path = os.path.join(output_dir, 'stats.json')
    try:
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        logger.info(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_path}")
    except Exception as e:
        logger.warning(f"ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

    logger.info(f"ä»»åŠ¡å®Œæˆ! ä»£ç†èŠ‚ç‚¹: {stats['proxy_count']}, è§„åˆ™: {stats['rule_count']}")


if __name__ == '__main__':
    main()
