#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Clashé…ç½®æ–‡ä»¶æ•´åˆå·¥å…·
ä»GitHubç§æœ‰ä»“åº“è¯»å–å¤šä¸ªè®¢é˜…YAMLæ–‡ä»¶ï¼Œæ•´åˆä»£ç†èŠ‚ç‚¹å’Œè§„åˆ™ï¼Œç”Ÿæˆç»Ÿä¸€çš„Clashé…ç½®
"""

import os
import sys
import yaml
import requests
import base64
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging

# è®¾ç½®é»˜è®¤ç¼–ç 
import locale
import codecs

# å¼ºåˆ¶è®¾ç½®UTF-8ç¼–ç 
os.environ['PYTHONIOENCODING'] = 'utf-8'
os.environ['PYTHONUTF8'] = '1'

# ç¡®ä¿UTF-8ç¼–ç 
try:
    if hasattr(sys.stdout, 'buffer') and sys.stdout.encoding != 'utf-8':
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
    if hasattr(sys.stderr, 'buffer') and sys.stderr.encoding != 'utf-8':
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')
except:
    pass  # åœ¨æŸäº›ç¯å¢ƒä¸‹å¯èƒ½ä¼šå¤±è´¥ï¼Œå¿½ç•¥é”™è¯¯

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ClashConfigMerger:
    def __init__(self, github_token: str = None, repo_owner: str = None, repo_name: str = None, local_mode: bool = False):
        """
        åˆå§‹åŒ–Clashé…ç½®åˆå¹¶å™¨

        Args:
            github_token: GitHubè®¿é—®ä»¤ç‰Œ
            repo_owner: ä»“åº“æ‰€æœ‰è€…
            repo_name: ä»“åº“åç§°
            local_mode: æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å¼
        """
        self.local_mode = local_mode
        self.github_token = github_token
        self.repo_owner = repo_owner
        self.repo_name = repo_name

        if not local_mode:
            self.headers = {
                'Authorization': f'token {github_token}',
                'Accept': 'application/vnd.github.v3+json'
            }
            self.base_url = f'https://api.github.com/repos/{repo_owner}/{repo_name}/contents'
        
    def load_config() -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        config_path = "config/settings.yaml"
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            sys.exit(1)
        except yaml.YAMLError as e:
            print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
            sys.exit(1)

    def get_file_content(self, file_path: str) -> Optional[str]:
        """
        è·å–æ–‡ä»¶å†…å®¹ï¼ˆæ”¯æŒæœ¬åœ°å’ŒGitHubæ¨¡å¼ï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å›None
        """
        if self.local_mode:
            # æœ¬åœ°æ¨¡å¼ï¼šç›´æ¥è¯»å–æ–‡ä»¶
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    logger.info(f"æˆåŠŸè¯»å–æœ¬åœ°æ–‡ä»¶: {file_path}")
                    return content
            except FileNotFoundError:
                logger.error(f"æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            except Exception as e:
                logger.error(f"è¯»å–æœ¬åœ°æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return None
        else:
            # GitHubæ¨¡å¼ï¼šé€šè¿‡APIè·å–
            try:
                url = f'{self.base_url}/{file_path}'
                response = requests.get(url, headers=self.headers)
                response.raise_for_status()

                file_data = response.json()
                if file_data['encoding'] == 'base64':
                    content = base64.b64decode(file_data['content']).decode('utf-8')
                    logger.info(f"æˆåŠŸè·å–æ–‡ä»¶: {file_path}")
                    return content
                else:
                    logger.error(f"ä¸æ”¯æŒçš„ç¼–ç æ ¼å¼: {file_data['encoding']}")
                    return None

            except requests.exceptions.RequestException as e:
                logger.error(f"è·å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return None
            except Exception as e:
                logger.error(f"è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return None
    
    def load_yaml_content(self, content: str) -> Optional[Dict[str, Any]]:
        """
        è§£æYAMLå†…å®¹
        
        Args:
            content: YAMLå­—ç¬¦ä¸²å†…å®¹
            
        Returns:
            è§£æåçš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            return yaml.safe_load(content)
        except yaml.YAMLError as e:
            logger.error(f"YAMLè§£æå¤±è´¥: {e}")
            return None
    
    def get_directory_files(self, directory_path: str) -> List[str]:
        """
        è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ï¼ˆæ”¯æŒæœ¬åœ°å’ŒGitHubæ¨¡å¼ï¼‰

        Args:
            directory_path: ç›®å½•è·¯å¾„

        Returns:
            æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if self.local_mode:
            # æœ¬åœ°æ¨¡å¼ï¼šæ‰«ææœ¬åœ°ç›®å½•
            try:
                if not os.path.exists(directory_path):
                    logger.warning(f"æœ¬åœ°ç›®å½•ä¸å­˜åœ¨: {directory_path}")
                    return []

                file_paths = []
                for filename in os.listdir(directory_path):
                    if filename.endswith('.yaml') or filename.endswith('.yml'):
                        file_path = os.path.join(directory_path, filename)
                        file_paths.append(file_path)

                logger.info(f"å‘ç° {len(file_paths)} ä¸ªYAMLæ–‡ä»¶åœ¨æœ¬åœ°ç›®å½•: {directory_path}")
                return file_paths

            except Exception as e:
                logger.error(f"æ‰«ææœ¬åœ°ç›®å½•å¤±è´¥ {directory_path}: {e}")
                return []
        else:
            # GitHubæ¨¡å¼ï¼šé€šè¿‡APIè·å–
            try:
                url = f'{self.base_url}/{directory_path}'
                response = requests.get(url, headers=self.headers)
                response.raise_for_status()

                files = response.json()
                file_paths = []

                for file_info in files:
                    if file_info['type'] == 'file' and file_info['name'].endswith('.yaml'):
                        file_paths.append(file_info['path'])

                logger.info(f"å‘ç° {len(file_paths)} ä¸ªYAMLæ–‡ä»¶åœ¨ç›®å½•: {directory_path}")
                return file_paths

            except requests.exceptions.RequestException as e:
                logger.error(f"è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨å¤±è´¥ {directory_path}: {e}")
                return []
    
    def merge_proxies(self, configs_with_sources: List[tuple]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶å¤šä¸ªé…ç½®æ–‡ä»¶çš„ä»£ç†èŠ‚ç‚¹

        Args:
            configs_with_sources: é…ç½®æ–‡ä»¶å’Œæ¥æºä¿¡æ¯çš„å…ƒç»„åˆ—è¡¨ [(config, source_file), ...]

        Returns:
            åˆå¹¶åçš„ä»£ç†èŠ‚ç‚¹åˆ—è¡¨ï¼ˆåŒ…å«æ¥æºä¿¡æ¯ï¼‰
        """
        merged_proxies = []
        seen_names = set()

        for config, source_file in configs_with_sources:
            if 'proxies' in config and isinstance(config['proxies'], list):
                source_name = os.path.basename(source_file).replace('.yaml', '')
                for proxy in config['proxies']:
                    if isinstance(proxy, dict) and 'name' in proxy:
                        # é¿å…é‡å¤çš„ä»£ç†èŠ‚ç‚¹åç§°
                        original_name = proxy['name']
                        name = original_name
                        counter = 1

                        while name in seen_names:
                            name = f"{original_name}_{counter}"
                            counter += 1

                        proxy['name'] = name
                        proxy['_source_file'] = source_name  # æ·»åŠ æ¥æºæ ‡è¯†
                        seen_names.add(name)
                        merged_proxies.append(proxy)

        logger.info(f"åˆå¹¶äº† {len(merged_proxies)} ä¸ªä»£ç†èŠ‚ç‚¹")
        return merged_proxies
    
    def merge_rules(self, rule_files: List[str]) -> List[str]:
        """
        åˆå¹¶è§„åˆ™åˆ—è¡¨ï¼ˆåªä½¿ç”¨ruleç›®å½•ä¸‹çš„è§„åˆ™æ–‡ä»¶ï¼‰

        Args:
            rule_files: è§„åˆ™æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            åˆå¹¶åçš„è§„åˆ™åˆ—è¡¨
        """
        merged_rules = []
        seen_rules = set()

        # åªä»è§„åˆ™æ–‡ä»¶ä¸­åŠ è½½è§„åˆ™ï¼Œå¿½ç•¥subæ–‡ä»¶ä¸­çš„è§„åˆ™
        for rule_file_path in rule_files:
            content = self.get_file_content(rule_file_path)
            if content:
                rule_data = self.load_yaml_content(content)
                if rule_data and 'payload' in rule_data:
                    rule_file_name = os.path.basename(rule_file_path).replace('.yaml', '')
                    logger.info(f"å¤„ç†è§„åˆ™æ–‡ä»¶: {rule_file_name}")

                    for rule in rule_data['payload']:
                        if isinstance(rule, str) and rule not in seen_rules:
                            # ç¡®ä¿è§„åˆ™æ ¼å¼æ­£ç¡®ï¼Œæ‰€æœ‰è§„åˆ™éƒ½æŒ‡å‘"ç½‘ç»œä»£ç†"
                            rule = rule.strip()
                            if rule:
                                # æ‰€æœ‰è§„åˆ™éƒ½æŒ‡å‘"ç½‘ç»œä»£ç†"ç»„
                                formatted_rule = f"{rule},ç½‘ç»œä»£ç†"
                                merged_rules.append(formatted_rule)
                                seen_rules.add(formatted_rule)

        logger.info(f"åˆå¹¶äº† {len(merged_rules)} æ¡è§„åˆ™")
        return merged_rules
    
    def create_proxy_groups(self, proxies: List[Dict[str, Any]], sub_files: List[str], rule_files: List[str]) -> List[Dict[str, Any]]:
        """
        åˆ›å»ºä»£ç†ç»„ç»“æ„

        Args:
            proxies: ä»£ç†èŠ‚ç‚¹åˆ—è¡¨
            sub_files: è®¢é˜…æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            rule_files: è§„åˆ™æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            ä»£ç†ç»„é…ç½®åˆ—è¡¨
        """
        proxy_names = [proxy['name'] for proxy in proxies if 'name' in proxy]

        # æŒ‰è®¢é˜…æ–‡ä»¶åˆ†ç»„ä»£ç†èŠ‚ç‚¹ - åŸºäºæ¥æºä¿¡æ¯è¿›è¡Œç²¾ç¡®åˆ†ç»„
        sub_groups = {}
        for file_path in sub_files:
            # ä»æ–‡ä»¶è·¯å¾„æå–æ–‡ä»¶åä½œä¸ºåˆ†ç»„å
            file_name = os.path.basename(file_path).replace('.yaml', '')
            sub_groups[file_name] = []

        # æ ¹æ®ä»£ç†çš„æ¥æºä¿¡æ¯è¿›è¡Œç²¾ç¡®åˆ†ç»„
        for proxy in proxies:
            if isinstance(proxy, dict) and '_source_file' in proxy:
                source_name = proxy['_source_file']
                proxy_name = proxy.get('name', '')
                if source_name in sub_groups and proxy_name:
                    sub_groups[source_name].append(proxy_name)

        # åˆ›å»ºä»£ç†ç»„åˆ—è¡¨
        proxy_groups = []

        # 1. åˆ›å»ºä¸»ç½‘ç»œä»£ç†ç»„ï¼ˆåªåŒ…å«subåˆ†ç»„ï¼Œä¸åŒ…å«ruleåˆ†ç»„ï¼‰
        sub_group_names = list(sub_groups.keys())

        network_proxy_options = ['è‡ªåŠ¨é€‰æ‹©', 'æ•…éšœè½¬ç§»'] + sub_group_names
        proxy_groups.append({
            'name': 'ç½‘ç»œä»£ç†',
            'type': 'select',
            'proxies': network_proxy_options
        })

        # 2. åˆ›å»ºè‡ªåŠ¨é€‰æ‹©å’Œæ•…éšœè½¬ç§»ç»„
        proxy_groups.extend([
            {
                'name': 'è‡ªåŠ¨é€‰æ‹©',
                'type': 'url-test',
                'proxies': proxy_names,
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300
            },
            {
                'name': 'æ•…éšœè½¬ç§»',
                'type': 'fallback',
                'proxies': proxy_names,
                'url': 'http://www.gstatic.com/generate_204',
                'interval': 300
            }
        ])

        # 3. ä¸ºæ¯ä¸ªè®¢é˜…æ–‡ä»¶åˆ›å»ºä»£ç†ç»„ï¼ˆåªä¸ºsubæ–‡ä»¶åˆ›å»ºï¼Œä¸ä¸ºruleæ–‡ä»¶åˆ›å»ºï¼‰
        for sub_name, sub_proxies in sub_groups.items():
            if sub_proxies:
                proxy_groups.append({
                    'name': sub_name,
                    'type': 'select',
                    'proxies': ['è‡ªåŠ¨é€‰æ‹©', 'æ•…éšœè½¬ç§»'] + sub_proxies
                })

        logger.info(f"åˆ›å»ºäº† {len(proxy_groups)} ä¸ªä»£ç†ç»„")
        return proxy_groups

    def create_base_config(self) -> Dict[str, Any]:
        """
        åˆ›å»ºåŸºç¡€é…ç½®

        Returns:
            åŸºç¡€é…ç½®å­—å…¸
        """
        return {
            'mixed-port': 7890,
            'allow-lan': True,
            'bind-address': '*',
            'mode': 'rule',
            'log-level': 'info',
            'external-controller': '127.0.0.1:9090',
            'dns': {
                'enable': True,
                'ipv6': False,
                'default-nameserver': ['223.5.5.5', '119.29.29.29', '114.114.114.114'],
                'enhanced-mode': 'fake-ip',
                'fake-ip-range': '198.18.0.1/16',
                'use-hosts': True,
                'nameserver': ['223.5.5.5', '119.29.29.29', '114.114.114.114'],
                'fallback': ['1.1.1.1', '8.8.8.8'],
                'fallback-filter': {
                    'geoip': True,
                    'geoip-code': 'CN',
                    'ipcidr': ['240.0.0.0/4']
                }
            }
        }

    def generate_merged_config(self, sub_directory: str = 'sub', rule_directory: str = 'rule') -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆå¹¶åçš„é…ç½®æ–‡ä»¶

        Args:
            sub_directory: è®¢é˜…æ–‡ä»¶ç›®å½•
            rule_directory: è§„åˆ™æ–‡ä»¶ç›®å½•

        Returns:
            åˆå¹¶åçš„å®Œæ•´é…ç½®
        """
        logger.info("å¼€å§‹ç”Ÿæˆåˆå¹¶é…ç½®...")

        # è·å–è®¢é˜…æ–‡ä»¶åˆ—è¡¨
        sub_files = self.get_directory_files(sub_directory)
        if not sub_files:
            logger.warning(f"æœªæ‰¾åˆ°è®¢é˜…æ–‡ä»¶åœ¨ç›®å½•: {sub_directory}")

        # è·å–è§„åˆ™æ–‡ä»¶åˆ—è¡¨
        rule_files = self.get_directory_files(rule_directory)
        if not rule_files:
            logger.warning(f"æœªæ‰¾åˆ°è§„åˆ™æ–‡ä»¶åœ¨ç›®å½•: {rule_directory}")

        # åŠ è½½æ‰€æœ‰è®¢é˜…é…ç½®
        configs_with_sources = []
        for file_path in sub_files:
            content = self.get_file_content(file_path)
            if content:
                config = self.load_yaml_content(content)
                if config:
                    configs_with_sources.append((config, file_path))

        if not configs_with_sources:
            logger.error("æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆçš„è®¢é˜…é…ç½®æ–‡ä»¶")
            return {}

        # åˆ›å»ºåŸºç¡€é…ç½®
        merged_config = self.create_base_config()

        # åˆå¹¶ä»£ç†èŠ‚ç‚¹
        merged_proxies = self.merge_proxies(configs_with_sources)
        merged_config['proxies'] = merged_proxies

        # åˆ›å»ºä»£ç†ç»„ï¼ˆä¼ å…¥æ–‡ä»¶åˆ—è¡¨ç”¨äºåˆ›å»ºå¯¹åº”çš„åˆ†ç»„ï¼‰
        proxy_groups = self.create_proxy_groups(merged_proxies, sub_files, rule_files)
        merged_config['proxy-groups'] = proxy_groups

        # åˆå¹¶è§„åˆ™ï¼ˆåªä½¿ç”¨ruleç›®å½•ä¸‹çš„è§„åˆ™ï¼‰
        merged_rules = self.merge_rules(rule_files)

        # åªæ·»åŠ æœ€åŸºæœ¬çš„é»˜è®¤è§„åˆ™
        default_rules = [
            'MATCH,DIRECT'  # é»˜è®¤æµé‡èµ°ç½‘ç»œä»£ç†ç»„
        ]

        merged_config['rules'] = merged_rules + default_rules

        # æ¸…ç†ä»£ç†èŠ‚ç‚¹ä¸­çš„ä¸´æ—¶å­—æ®µ
        for proxy in merged_config.get('proxies', []):
            if isinstance(proxy, dict) and '_source_file' in proxy:
                del proxy['_source_file']

        logger.info("é…ç½®åˆå¹¶å®Œæˆ")
        return merged_config

    def save_config_to_file(self, config: Dict[str, Any], output_path: str) -> bool:
        """
        ä¿å­˜é…ç½®åˆ°æ–‡ä»¶

        Args:
            config: é…ç½®å­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            # ä½¿ç”¨UTF-8 BOMç¼–ç å†™å…¥æ–‡ä»¶ï¼Œç¡®ä¿GitHub Pagesæ­£ç¡®è¯†åˆ«
            with open(output_path, 'w', encoding='utf-8-sig', newline='\n') as f:
                # ä½¿ç”¨è‡ªå®šä¹‰çš„YAMLè¾“å‡ºæ ¼å¼ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º
                yaml_content = yaml.dump(config,
                                        default_flow_style=False,
                                        allow_unicode=True,
                                        sort_keys=False,
                                        encoding=None,  # è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—èŠ‚
                                        width=1000,     # é¿å…é•¿è¡Œè¢«æŠ˜æ–­
                                        indent=2)
                # ç¡®ä¿å†™å…¥UTF-8ç¼–ç çš„å†…å®¹
                f.write(yaml_content)

            logger.info(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æµ‹è¯•æ¨¡å¼
    local_mode = len(sys.argv) > 1 and sys.argv[1] == '--local'

    if local_mode:
        logger.info("ğŸ§ª æœ¬åœ°æµ‹è¯•æ¨¡å¼")
        # æœ¬åœ°æ¨¡å¼é…ç½®
        merger = ClashConfigMerger(local_mode=True)
        output_dir = 'output'
        sub_dir = 'sub'
        rule_dir = 'rule'
        auth_token = 'local-test'
    else:
        logger.info("â˜ï¸ GitHubæ¨¡å¼")
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        github_token = os.getenv('GITHUB_TOKEN')
        repo_owner = os.getenv('REPO_OWNER', 'your-username')
        repo_name = os.getenv('REPO_NAME', 'clash-config')
        output_dir = os.getenv('OUTPUT_DIR', 'docs')
        auth_token = os.getenv('AUTH_TOKEN', 'default-token')
        
        loadedConfig = load_config()
        subscription_directory = loadedConfig['github']['subscription_directory']
        rules_directory = loadedConfig['github']['rules_directory']
        
        sub_dir = 'sub'
        if not subscription_directory
            sub_dir = subscription_directory
        
        rule_dir = 'rule'
        if not rules_directory
            rule_dir = rules_directory

        if not github_token:
            logger.error("æœªè®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡")
            sys.exit(1)

        # åˆ›å»ºåˆå¹¶å™¨å®ä¾‹
        merger = ClashConfigMerger(github_token, repo_owner, repo_name, local_mode=False)

    # ç”Ÿæˆåˆå¹¶é…ç½®
    merged_config = merger.generate_merged_config(sub_dir, rule_dir)

    if not merged_config:
        logger.error("ç”Ÿæˆé…ç½®å¤±è´¥")
        sys.exit(1)

    # ä½¿ç”¨tokenä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†è¿›è¡Œè®¤è¯
    config_filename = f'clash-{auth_token}.yaml'
    config_filename_dot = f'clash-xxxxxx.yaml'
    output_path = os.path.join(output_dir, config_filename)
    output_path_dot = os.path.join(output_dir, config_filename_dot)
    if not merger.save_config_to_file(merged_config, output_path):
        sys.exit(1)

    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    stats = {
        'generated_at': datetime.now().isoformat(),
        'proxy_count': len(merged_config.get('proxies', [])),
        'proxy_group_count': len(merged_config.get('proxy-groups', [])),
        'rule_count': len(merged_config.get('rules', [])),
        'config_filename': config_filename  # æ·»åŠ é…ç½®æ–‡ä»¶åä¿¡æ¯
    }

    stats_path = os.path.join(output_dir, 'stats.json')
    try:
        os.makedirs(output_dir, exist_ok=True)
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        logger.info(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_path}")
    except Exception as e:
        logger.warning(f"ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

    logger.info(f"âœ… ä»»åŠ¡å®Œæˆ! ä»£ç†èŠ‚ç‚¹: {stats['proxy_count']}, è§„åˆ™: {stats['rule_count']}")
    logger.info(f"ğŸ“ é…ç½®æ–‡ä»¶: {config_filename_dot}")
    if local_mode:
        logger.info(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path_dot}")


if __name__ == '__main__':
    main()
