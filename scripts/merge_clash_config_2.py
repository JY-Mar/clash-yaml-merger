#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Clashé…ç½®æ–‡ä»¶æ•´åˆå·¥å…·
ä»GitHubç§æœ‰ä»“åº“è¯»å–å¤šä¸ªè®¢é˜…YAMLæ–‡ä»¶ï¼Œæ•´åˆä»£ç†èŠ‚ç‚¹å’Œè§„åˆ™ï¼Œç”Ÿæˆç»Ÿä¸€çš„Clashé…ç½®
"""

from copy import deepcopy
import getpass
import os
import re
import sys
import yaml
import requests
import base64
import json
from datetime import datetime, timezone
from typing import Dict, List, Any, Optional
import logging
from functools import reduce

# è®¾ç½®é»˜è®¤ç¼–ç 
import locale
import codecs

# å¼ºåˆ¶è®¾ç½®UTF-8ç¼–ç 
os.environ["PYTHONIOENCODING"] = "utf-8"
os.environ["PYTHONUTF8"] = "1"

# ç¡®ä¿UTF-8ç¼–ç 
try:
    if hasattr(sys.stdout, "buffer") and sys.stdout.encoding != "utf-8":
        sys.stdout = codecs.getwriter("utf-8")(sys.stdout.buffer, "strict")
    if hasattr(sys.stderr, "buffer") and sys.stderr.encoding != "utf-8":
        sys.stderr = codecs.getwriter("utf-8")(sys.stderr.buffer, "strict")
except:
    pass  # åœ¨æŸäº›ç¯å¢ƒä¸‹å¯èƒ½ä¼šå¤±è´¥ï¼Œå¿½ç•¥é”™è¯¯

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ç‰ˆæœ¬1ã€2ã€3
version_flag: int = 2
# ç‰ˆæœ¬æ–‡ä»¶åç¼€
version_file_suffix = f"-CornSS"


def deep_merge(a: Any, b: Any) -> Any:
    """
    æ·±åˆå¹¶ï¼Œå°†båˆå¹¶åˆ°aä¸­

    Args:
        a: åˆå¹¶å¯¹è±¡1
        b: åˆå¹¶å¯¹è±¡2

    Returns:
        æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å›None
    """
    # ç±»å‹ä¸€è‡´æ‰åˆå¹¶
    if type(a) != type(b):
        return deepcopy(b)

    # åˆå¹¶ dictï¼ˆMapï¼‰
    if isinstance(a, dict):
        result = deepcopy(a)
        for key, value in b.items():
            if key in result:
                result[key] = deep_merge(result[key], value)
            else:
                result[key] = deepcopy(value)
        return result

    # åˆå¹¶ list
    elif isinstance(a, list):
        return deepcopy(a) + deepcopy(b)

    # åˆå¹¶ set
    elif isinstance(a, set):
        return deepcopy(a) | deepcopy(b)

    # åˆå¹¶å¯¹è±¡ï¼ˆè‡ªå®šä¹‰ç±»ï¼‰
    elif hasattr(a, "__dict__") and hasattr(b, "__dict__"):
        result = deepcopy(a)
        for attr in b.__dict__:
            if hasattr(result, attr):
                merged_value = deep_merge(getattr(result, attr), getattr(b, attr))
                setattr(result, attr, merged_value)
            else:
                setattr(result, attr, deepcopy(getattr(b, attr)))
        return result

    # åŸºç¡€ç±»å‹ç›´æ¥æ›¿æ¢
    else:
        return deepcopy(b)


def load_config() -> Dict[str, Any]:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = "config/settings.yaml"
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
            owner = f"{config['github']['owner']}".strip()
            if owner:
                config["github"]["owner"] = owner

            repo = f"{config['github']['repository']}".strip()
            if repo:
                config["github"]["repository"] = repo

            fconf_r_fs = f"{config['github']['fconf_remote_files']}".strip()

            fconf_dirs = f"{config['github'][f'fconf_directories_{version_flag}']}".strip()
            if fconf_dirs and fconf_r_fs:
                config["github"][f'fconf_directories_{version_flag}'] = ",".join(
                    list(dict.fromkeys(fconf_r_fs.split(",") + fconf_dirs.split(",")))
                )
            elif fconf_dirs and not fconf_r_fs:
                config["github"][f'fconf_directories_{version_flag}'] = fconf_dirs

            sub_dir = f"{config['github']['sub_directory']}".strip()
            if sub_dir:
                config["github"]["sub_directory"] = sub_dir

            rule_dir = f"{config['github']['rule_directory']}".strip()
            if rule_dir:
                config["github"]["rule_directory"] = rule_dir

            return config
    except FileNotFoundError:
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)
    except yaml.YAMLError as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        sys.exit(1)


# settings.yaml é…ç½®
settings_config = load_config()

# è¿œç¨‹YAMLæ–‡ä»¶æ­£åˆ™è¡¨è¾¾å¼
remote_yaml_pattern = r"^https:\/\/.+\.yaml$"


class ClashConfigMerger:
    def __init__(
        self,
        github_token: str = None,
        repo_owner: str = None,
        repo_name: str = None,
        local_mode: bool = False,
    ):
        """
        åˆå§‹åŒ–Clashé…ç½®åˆå¹¶å™¨

        Args:
            github_token: GitHubè®¿é—®ä»¤ç‰Œ
            repo_owner: ä»“åº“æ‰€æœ‰è€…
            repo_name: ä»“åº“åç§°
            local_mode: æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å¼
        """
        self.local_mode = local_mode
        self.github_token = github_token
        self.repo_owner = repo_owner
        self.repo_name = repo_name

        if not local_mode:
            self.headers = {
                "Authorization": f"token {github_token}",
                "Accept": "application/vnd.github.v3+json",
            }
            self.base_url = (
                f"https://api.github.com/repos/{repo_owner}/{repo_name}/contents"
            )

    def get_file_content(self, file_path: str) -> Optional[str]:
        """
        è·å–æ–‡ä»¶å†…å®¹ï¼ˆæ”¯æŒæœ¬åœ°å’ŒGitHubæ¨¡å¼ï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²ï¼Œå¤±è´¥è¿”å›None
        """
        if self.local_mode:
            # æœ¬åœ°æ¨¡å¼ï¼šç›´æ¥è¯»å–æ–‡ä»¶
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read()
                    logger.info(f"æˆåŠŸè¯»å–æœ¬åœ°æ–‡ä»¶: {file_path}")
                    return content
            except FileNotFoundError:
                logger.error(f"æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None
            except Exception as e:
                logger.error(f"è¯»å–æœ¬åœ°æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return None
        else:
            # GitHubæ¨¡å¼ï¼šé€šè¿‡APIè·å–
            try:
                if re.fullmatch(remote_yaml_pattern, file_path) is not None:
                    # æ˜¯yamlæ–‡ä»¶è·¯å¾„ç›´æ¥è¯»å–
                    url = file_path
                    response = requests.get(url)
                    try:
                        yaml_raw_content = response.text
                    except json.JSONDecodeError as e:
                        yaml_raw_content = None
                        logger.error(f"è§£æå¤±è´¥ï¼šä¸æ˜¯åˆæ³•çš„ JSON æ ¼å¼: {e}")

                    if yaml_raw_content:
                        logger.info(f"æˆåŠŸè·å–æ–‡ä»¶: {file_path}")

                    return yaml_raw_content
                else:
                    url = f"{self.base_url}/{file_path}"
                    response = requests.get(url, headers=self.headers)
                    response.raise_for_status()
                    file_data = response.json()

                if file_data["encoding"] == "base64":
                    content = base64.b64decode(file_data["content"]).decode("utf-8")
                    logger.info(f"æˆåŠŸè·å–æ–‡ä»¶: {file_path}")
                    return content
                else:
                    logger.error(f"ä¸æ”¯æŒçš„ç¼–ç æ ¼å¼: {file_data['encoding']}")
                    return None

            except requests.exceptions.RequestException as e:
                logger.error(f"è·å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return None
            except Exception as e:
                logger.error(f"è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                return None

    def load_yaml_content(self, content: str) -> Optional[Dict[str, Any]]:
        """
        è§£æYAMLå†…å®¹

        Args:
            content: YAMLå­—ç¬¦ä¸²å†…å®¹

        Returns:
            è§£æåçš„å­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            return yaml.safe_load(content)
        except yaml.YAMLError as e:
            logger.error(f"YAMLè§£æå¤±è´¥: {e}")
            return None

    def get_directory_files(self, directory_path: str) -> List[str]:
        """
        è·å–ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ï¼ˆæ”¯æŒæœ¬åœ°å’ŒGitHubæ¨¡å¼ï¼‰

        Args:
            directory_path: ç›®å½•è·¯å¾„

        Returns:
            æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if self.local_mode:
            # æœ¬åœ°æ¨¡å¼ï¼šæ‰«ææœ¬åœ°ç›®å½•
            try:
                if not os.path.exists(directory_path):
                    logger.warning(f"æœ¬åœ°ç›®å½•ä¸å­˜åœ¨: {directory_path}")
                    return []

                file_paths = []
                for filename in os.listdir(directory_path):
                    if filename.endswith(".yaml") or filename.endswith(".yml"):
                        file_path = os.path.join(directory_path, filename)
                        file_paths.append(file_path)

                logger.info(
                    f"å‘ç° {len(file_paths)} ä¸ªYAMLæ–‡ä»¶åœ¨æœ¬åœ°ç›®å½•: {directory_path}"
                )
                return file_paths

            except Exception as e:
                logger.error(f"æ‰«ææœ¬åœ°ç›®å½•å¤±è´¥ {directory_path}: {e}")
                return []
        else:
            # GitHubæ¨¡å¼ï¼šé€šè¿‡APIè·å–
            try:
                url = f"{self.base_url}/{directory_path}"
                response = requests.get(url, headers=self.headers)
                response.raise_for_status()

                files = response.json()
                file_paths = []

                for file_info in files:
                    if file_info["type"] == "file" and file_info["name"].endswith(
                        ".yaml"
                    ):
                        file_paths.append(file_info["path"])

                logger.info(
                    f"å‘ç° {len(file_paths)} ä¸ªYAMLæ–‡ä»¶åœ¨ç›®å½•: {directory_path}"
                )
                return file_paths

            except requests.exceptions.RequestException as e:
                logger.error(f"è·å–ç›®å½•æ–‡ä»¶åˆ—è¡¨å¤±è´¥ {directory_path}: {e}")
                return []

    def merge_proxies(self, configs_with_sources: List[tuple]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶å¤šä¸ªé…ç½®æ–‡ä»¶çš„ä»£ç†èŠ‚ç‚¹

        Args:
            configs_with_sources: é…ç½®æ–‡ä»¶å’Œæ¥æºä¿¡æ¯çš„å…ƒç»„åˆ—è¡¨ [(config, source_file), ...]

        Returns:
            åˆå¹¶åçš„ä»£ç†èŠ‚ç‚¹åˆ—è¡¨ï¼ˆåŒ…å«æ¥æºä¿¡æ¯ï¼‰
        """
        merged_proxies = []
        seen_names = set()

        for config, source_file in configs_with_sources:
            if "proxies" in config and isinstance(config["proxies"], list):
                source_name = os.path.basename(source_file).replace(".yaml", "")
                for proxy in config["proxies"]:
                    if isinstance(proxy, dict) and "name" in proxy:
                        # é¿å…é‡å¤çš„ä»£ç†èŠ‚ç‚¹åç§°
                        original_name = proxy["name"]
                        name = original_name
                        counter = 1

                        while name in seen_names:
                            name = f"{original_name}_{counter}"
                            counter += 1

                        proxy["name"] = name
                        proxy["_source_file"] = source_name  # æ·»åŠ æ¥æºæ ‡è¯†
                        seen_names.add(name)
                        merged_proxies.append(proxy)

        logger.info(f"åˆå¹¶äº† {len(merged_proxies)} ä¸ªä»£ç†èŠ‚ç‚¹")
        return merged_proxies

    def merge_rules(self, rule_files: List[str]) -> List[str]:
        """
        åˆå¹¶è§„åˆ™åˆ—è¡¨ï¼ˆåªä½¿ç”¨ruleç›®å½•ä¸‹çš„è§„åˆ™æ–‡ä»¶ï¼‰

        Args:
            rule_files: è§„åˆ™æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            åˆå¹¶åçš„è§„åˆ™åˆ—è¡¨
        """
        merged_rules = []
        seen_rules = set()

        # åªä»è§„åˆ™æ–‡ä»¶ä¸­åŠ è½½è§„åˆ™ï¼Œå¿½ç•¥subæ–‡ä»¶ä¸­çš„è§„åˆ™
        for rule_file_path in rule_files:
            content = self.get_file_content(rule_file_path)
            if content:
                rule_data = self.load_yaml_content(content)
                logger.info(f"è§„åˆ™æ–‡ä»¶ {rule_file_path}")
                if rule_data and "payload" in rule_data:
                    rule_file_name = os.path.basename(rule_file_path).replace(
                        ".yaml", ""
                    )
                    logger.info(f"å¤„ç†è§„åˆ™æ–‡ä»¶: {rule_file_name}")

                    for rule in rule_data["payload"]:
                        if isinstance(rule, str) and rule not in seen_rules:
                            # ç¡®ä¿è§„åˆ™æ ¼å¼æ­£ç¡®ï¼Œæ‰€æœ‰è§„åˆ™éƒ½æŒ‡å‘"ç½‘ç»œä»£ç†"
                            rule = rule.strip()
                            if rule:
                                # æ‰€æœ‰è§„åˆ™éƒ½æŒ‡å‘"ç½‘ç»œä»£ç†"ç»„
                                formatted_rule = f"{rule},ç½‘ç»œä»£ç†"
                                merged_rules.append(formatted_rule)
                                seen_rules.add(formatted_rule)

        logger.info(f"åˆå¹¶äº† {len(merged_rules)} æ¡è§„åˆ™")
        return merged_rules

    def create_proxy_groups(
        self, proxies: List[Dict[str, Any]], sub_files: List[str], rule_files: List[str]
    ) -> List[Dict[str, Any]]:
        """
        åˆ›å»ºä»£ç†ç»„ç»“æ„

        Args:
            proxies: ä»£ç†èŠ‚ç‚¹åˆ—è¡¨
            sub_files: è®¢é˜…æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            rule_files: è§„åˆ™æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            ä»£ç†ç»„é…ç½®åˆ—è¡¨
        """
        proxy_names = [proxy["name"] for proxy in proxies if "name" in proxy]

        # æŒ‰è®¢é˜…æ–‡ä»¶åˆ†ç»„ä»£ç†èŠ‚ç‚¹ - åŸºäºæ¥æºä¿¡æ¯è¿›è¡Œç²¾ç¡®åˆ†ç»„
        sub_groups = {}
        for file_path in sub_files:
            # ä»æ–‡ä»¶è·¯å¾„æå–æ–‡ä»¶åä½œä¸ºåˆ†ç»„å
            file_name = os.path.basename(file_path).replace(".yaml", "")
            sub_groups[file_name] = []

        # æ ¹æ®ä»£ç†çš„æ¥æºä¿¡æ¯è¿›è¡Œç²¾ç¡®åˆ†ç»„
        for proxy in proxies:
            if isinstance(proxy, dict) and "_source_file" in proxy:
                source_name = proxy["_source_file"]
                proxy_name = proxy.get("name", "")
                if source_name in sub_groups and proxy_name:
                    sub_groups[source_name].append(proxy_name)

        # åˆ›å»ºä»£ç†ç»„åˆ—è¡¨
        proxy_groups = []

        # 1. åˆ›å»ºä¸»ç½‘ç»œä»£ç†ç»„ï¼ˆåªåŒ…å«subåˆ†ç»„ï¼Œä¸åŒ…å«ruleåˆ†ç»„ï¼‰
        sub_group_names = list(sub_groups.keys())

        network_proxy_options = ["è‡ªåŠ¨é€‰æ‹©", "æ•…éšœè½¬ç§»"] + sub_group_names
        proxy_groups.append(
            {"name": "ç½‘ç»œä»£ç†", "type": "select", "proxies": network_proxy_options}
        )

        # 2. åˆ›å»ºè‡ªåŠ¨é€‰æ‹©å’Œæ•…éšœè½¬ç§»ç»„
        proxy_groups.extend(
            [
                {
                    "name": "è‡ªåŠ¨é€‰æ‹©",
                    "type": "url-test",
                    "proxies": proxy_names,
                    "url": "http://www.gstatic.com/generate_204",
                    "interval": 300,
                },
                {
                    "name": "æ•…éšœè½¬ç§»",
                    "type": "fallback",
                    "proxies": proxy_names,
                    "url": "http://www.gstatic.com/generate_204",
                    "interval": 300,
                },
            ]
        )

        # 3. ä¸ºæ¯ä¸ªè®¢é˜…æ–‡ä»¶åˆ›å»ºä»£ç†ç»„ï¼ˆåªä¸ºsubæ–‡ä»¶åˆ›å»ºï¼Œä¸ä¸ºruleæ–‡ä»¶åˆ›å»ºï¼‰
        for sub_name, sub_proxies in sub_groups.items():
            if sub_proxies:
                proxy_groups.append(
                    {
                        "name": sub_name,
                        "type": "select",
                        "proxies": ["è‡ªåŠ¨é€‰æ‹©", "æ•…éšœè½¬ç§»"] + sub_proxies,
                    }
                )

        logger.info(f"åˆ›å»ºäº† {len(proxy_groups)} ä¸ªä»£ç†ç»„")
        return proxy_groups

    def create_base_config(self) -> Dict[str, Any]:
        """
        åˆ›å»ºåŸºç¡€é…ç½®

        Returns:
            åŸºç¡€é…ç½®å­—å…¸
        """
        return {
            "mixed-port": 7890,
            "allow-lan": True,
            "bind-address": "*",
            "mode": "rule",
            "log-level": "info",
            "external-controller": "127.0.0.1:9090",
            "dns": {
                "enable": True,
                "ipv6": False,
                "default-nameserver": ["223.5.5.5", "119.29.29.29", "114.114.114.114"],
                "enhanced-mode": "fake-ip",
                "fake-ip-range": "198.18.0.1/16",
                "use-hosts": True,
                "nameserver": ["223.5.5.5", "119.29.29.29", "114.114.114.114"],
                "fallback": ["1.1.1.1", "8.8.8.8"],
                "fallback-filter": {
                    "geoip": True,
                    "geoip-code": "CN",
                    "ipcidr": ["240.0.0.0/4"],
                },
            },
        }

    def generate_merged_config(
        self,
        fconf_directories: List[str] = ["fconfs"],
        sub_directory: str = "proxies",
        rule_directory: str = "rules",
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆåˆå¹¶åçš„é…ç½®æ–‡ä»¶

        Args:
            fconf_directories: å…¨é‡é…ç½®æ–‡ä»¶ç›®å½•ï¼Œæ”¯æŒç§æœ‰ä»“åº“ç›®å½•ã€å•ç‹¬æŒ‡å®šçš„yamlæ–‡ä»¶
            sub_directory: è®¢é˜…æ–‡ä»¶ç›®å½•
            rule_directory: è§„åˆ™æ–‡ä»¶ç›®å½•

        Returns:
            åˆå¹¶åçš„åŸºç¡€é…ç½®
        """

        logger.info(f"å¼€å§‹ç”Ÿæˆåˆå¹¶é…ç½®...")

        # 1. åˆ›å»ºåŸºç¡€é…ç½®
        merged_config = self.create_base_config()

        # 2.1.1 è·å–å…¨é‡é…ç½®æ–‡ä»¶åˆ—è¡¨
        fconf_files: List[str] = []
        if fconf_directories:
            for fconf_directory in fconf_directories:
                if re.fullmatch(remote_yaml_pattern, fconf_directory) is not None:
                    fconf_files.extend([fconf_directory])
                else:
                    fconf_files.extend(self.get_directory_files(fconf_directory))
        if not fconf_files:
            logger.warning(f"æœªæ‰¾åˆ°å…¨é‡é…ç½®æ–‡ä»¶åœ¨ç›®å½•: {fconf_directories}")

        # 2.1.2 ä»å…¨é‡é…ç½®æ–‡ä»¶åˆ—è¡¨åŠ è½½æ‰€æœ‰å…¨é‡é…ç½®
        configs_from_fconf_files: List[Dict[str, Any]] = []
        for file_path in fconf_files:
            content = self.get_file_content(file_path)
            if content:
                config = self.load_yaml_content(content)
                if config:
                    configs_from_fconf_files.append((config))

        if not configs_from_fconf_files:
            logger.error(f"æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆçš„å…¨é‡é…ç½®æ–‡ä»¶")
            return {}

        # 2.1.3 åˆå¹¶å…¨é‡é…ç½®
        if configs_from_fconf_files:
            merged_config = reduce(deep_merge, configs_from_fconf_files)

        # 2.2.1 è·å–è®¢é˜…æ–‡ä»¶åˆ—è¡¨
        sub_files = self.get_directory_files(sub_directory)
        if not sub_files:
            logger.warning(f"æœªæ‰¾åˆ°è®¢é˜…æ–‡ä»¶åœ¨ç›®å½•: {sub_directory}")

        # 2.2.2 åŠ è½½æ‰€æœ‰è®¢é˜…é…ç½®
        configs_from_sub_files = []
        for file_path in sub_files:
            content = self.get_file_content(file_path)
            if content:
                config = self.load_yaml_content(content)
                if config:
                    configs_from_sub_files.append((config, file_path))

        if not configs_from_sub_files:
            logger.error(f"æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆçš„è®¢é˜…é…ç½®æ–‡ä»¶")
            # return {}

        # 2.2.3 åˆå¹¶ä»£ç†èŠ‚ç‚¹
        if configs_from_sub_files:
            merged_proxies = self.merge_proxies(configs_from_sub_files)
            merged_config["proxies"] = merged_proxies
            # åˆ›å»ºä»£ç†ç»„ï¼ˆä¼ å…¥æ–‡ä»¶åˆ—è¡¨ç”¨äºåˆ›å»ºå¯¹åº”çš„åˆ†ç»„ï¼‰
            proxy_groups = self.create_proxy_groups(
                merged_proxies, sub_files, rule_files
            )
            merged_config["proxy-groups"] = proxy_groups

        # 2.3.1 è·å–è§„åˆ™æ–‡ä»¶åˆ—è¡¨
        rule_files = self.get_directory_files(rule_directory)
        if not rule_files:
            logger.warning(f"æœªæ‰¾åˆ°è§„åˆ™æ–‡ä»¶åœ¨ç›®å½•: {rule_directory}")

        # 2.3.2 åˆå¹¶è§„åˆ™ï¼ˆåªä½¿ç”¨ruleç›®å½•ä¸‹çš„è§„åˆ™ï¼‰
        merged_rules = self.merge_rules(rule_files)

        if merged_rules:
            # åªæ·»åŠ æœ€åŸºæœ¬çš„é»˜è®¤è§„åˆ™
            default_rules = ["MATCH,DIRECT"]  # é»˜è®¤æµé‡èµ°ç½‘ç»œä»£ç†ç»„

            merged_config["rules"] = merged_rules + default_rules

        # 3. æ¸…ç†ä»£ç†èŠ‚ç‚¹ä¸­çš„ä¸´æ—¶å­—æ®µ
        try:
            for proxy in merged_config.get("proxies", []):
                if isinstance(proxy, dict) and "_source_file" in proxy:
                    del proxy["_source_file"]
        except Exception as e:
            logger.error(f"æ¸…ç†ä»£ç†èŠ‚ç‚¹ä¸­çš„ä¸´æ—¶å­—æ®µå¤±è´¥: {e}")

        logger.info(f"é…ç½®åˆå¹¶å®Œæˆ")

        return merged_config

    def save_config_to_file(self, config: Dict[str, Any], output_path: str) -> bool:
        """
        ä¿å­˜é…ç½®åˆ°æ–‡ä»¶

        Args:
            config: é…ç½®å­—å…¸
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„

        Returns:
            ä¿å­˜æ˜¯å¦æˆåŠŸ
        """
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            # ä½¿ç”¨UTF-8 BOMç¼–ç å†™å…¥æ–‡ä»¶ï¼Œç¡®ä¿GitHub Pagesæ­£ç¡®è¯†åˆ«
            with open(output_path, "w", encoding="utf-8-sig", newline="\n") as f:
                # ä½¿ç”¨è‡ªå®šä¹‰çš„YAMLè¾“å‡ºæ ¼å¼ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º
                yaml_content = yaml.dump(
                    config,
                    default_flow_style=False,
                    allow_unicode=True,
                    sort_keys=False,
                    encoding=None,  # è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—èŠ‚
                    width=1000,  # é¿å…é•¿è¡Œè¢«æŠ˜æ–­
                    indent=2,
                )

                # æ’å…¥å¤´éƒ¨å†…å®¹
                header = [
                    "# Automatically generated `Clash` yaml file",
                    "# Do not modify manually",
                    f"# Last Update: {datetime.now(timezone.utc).isoformat()}",
                ]
                # åˆå¹¶ä¸ºæœ€ç»ˆæ–‡æœ¬
                final_yaml_content = "\n".join(header) + "\n\n" + yaml_content

                # ç¡®ä¿å†™å…¥UTF-8ç¼–ç çš„å†…å®¹
                f.write(final_yaml_content)

            logger.info(f"é…ç½®æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_path}")
            return True

        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False


class ClashConfigInitParams:
    def __init__(
        self,
        local_mode: bool = False,
        merger: ClashConfigMerger = None,
        auth_token: str = None,
        output_dir: str = None,
        fconf_dirs: list[str] = [],
        sub_dir: str = None,
        rule_dir: str = None,
    ):
        """
        åˆå§‹åŒ–Clashé…ç½®åˆå§‹åŒ–å‚æ•°

        Args:
            local_mode: æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å¼
            merger: Clashé…ç½®åˆå¹¶å¯¹è±¡
            auth_token: ç”¨æˆ·é‰´æƒä»¤ç‰Œ
            output_dir: è¾“å‡ºç›®å½•
            fconf_dirs: å…¨é‡é…ç½®ç›®å½•åˆ—è¡¨
            sub_dir: è®¢é˜…ç›®å½•
            rule_dir: è§„åˆ™ç›®å½•
        """
        self.local_mode = local_mode
        self.merger = merger
        self.output_dir = output_dir
        self.fconf_dirs = fconf_dirs
        self.sub_dir = sub_dir
        self.rule_dir = rule_dir
        self.auth_token = auth_token


def merger_init() -> ClashConfigInitParams:
    """
    åˆå§‹åŒ–mergerã€output_dirã€fconf_dirsã€sub_dirã€rule_dirã€auth_tokenç­‰é‡è¦å‚æ•°

    Returns:
        åˆå§‹åŒ–å‚æ•°å¯¹è±¡
    """

    # æ£€æŸ¥æ˜¯å¦ä¸ºæœ¬åœ°æµ‹è¯•æ¨¡å¼
    local_mode = len(sys.argv) > 1 and sys.argv[1] == "--local"

    if local_mode:
        logger.info(f"ğŸ§ª æœ¬åœ°æµ‹è¯•æ¨¡å¼")
        # æœ¬åœ°æ¨¡å¼é…ç½®
        merger = ClashConfigMerger(local_mode=True)
        output_dir = "output"
        fconf_dirs = ["fconfs"]
        sub_dir = "proxies"
        rule_dir = "rules"
        auth_token = "local-test"
    else:
        logger.info(f"â˜ï¸ GitHubæ¨¡å¼")
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        github_token = os.getenv("GITHUB_TOKEN")
        repo_owner = os.getenv("REPO_OWNER", "your-username")
        repo_name = os.getenv("REPO_NAME", "clash-config")
        output_dir = os.getenv("OUTPUT_DIR", "docs")
        auth_token = os.getenv("AUTH_TOKEN", "default-token")

        fconf_directories = settings_config["github"][f'fconf_directories_{version_flag}']
        sub_directory = settings_config["github"]["sub_directory"]
        rule_directory = settings_config["github"]["rule_directory"]

        fconf_dirs = ["fconfs"]
        if fconf_directories and isinstance(fconf_directories, str):
            if (
                "," in fconf_directories
                and not fconf_directories.startswith(",")
                and not fconf_directories.endswith(",")
            ):
                fconf_dirs = list(map(str.strip, fconf_directories.split(",")))
            else:
                fconf_dirs = [fconf_directories.strip()]

        sub_dir = "proxies"
        if sub_directory:
            sub_dir = sub_directory.strip()

        rule_dir = "rules"
        if rule_directory:
            rule_dir = rule_directory.strip()

        if not github_token:
            logger.error(f"æœªè®¾ç½®GITHUB_TOKENç¯å¢ƒå˜é‡")
            sys.exit(1)

        # åˆ›å»ºåˆå¹¶å™¨å®ä¾‹
        merger = ClashConfigMerger(
            github_token, repo_owner, repo_name, local_mode=False
        )

    return ClashConfigInitParams(
        local_mode=local_mode,
        merger=merger,
        output_dir=output_dir,
        fconf_dirs=fconf_dirs,
        sub_dir=sub_dir,
        rule_dir=rule_dir,
        auth_token=auth_token,
    )


def merger_gen_config():
    """
    ç”Ÿæˆåˆå¹¶åçš„é…ç½®
    """

    ida = merger_init()
    merged_config = ida.merger.generate_merged_config(
        ida.fconf_dirs, ida.sub_dir, ida.rule_dir
    )

    if not merged_config:
        logger.error(f"ç”Ÿæˆé…ç½®å¤±è´¥")
        sys.exit(1)

    # ä½¿ç”¨tokenä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†è¿›è¡Œè®¤è¯
    config_filename = f"{settings_config['output']['config_filename']}{version_file_suffix}-{ida.auth_token}.yaml"
    output_path = os.path.join(ida.output_dir, config_filename)
    if not ida.merger.save_config_to_file(merged_config, output_path):
        sys.exit(1)

    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    now_date_formatted = datetime.now(timezone.utc).isoformat()
    stats = {
        "generated_at": now_date_formatted,
        "proxy_providers_count": 0,
        "proxies_count": 0,
        "proxy_groups_count": 0,
        "rules_count": 0,
    }
    try:
        proxy_providers_count = len(merged_config.get("proxy-providers", {}))
        proxies_count = len(merged_config.get("proxies", {}))
        proxy_groups_count = len(merged_config.get("proxy-groups", {}))
        rules_count = len(merged_config.get("rules", {}))
        stats.update(
            {
                "proxy_providers_count": proxy_providers_count,
                "proxies_count": proxies_count,
                "proxy_groups_count": proxy_groups_count,
                "rules_count": rules_count,
            }
        )
    except Exception as e:
        logger.error(f"ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

    stats_path = os.path.join(
        ida.output_dir,
        f"{settings_config['output']['stats_filename']}{version_file_suffix}.json",
    )

    try:
        os.makedirs(ida.output_dir, exist_ok=True)
        with open(stats_path, "w", encoding="utf-8") as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)

        logger.info(f"ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_path}")
    except Exception as e:
        logger.warning(f"ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

    logger.info(
        f"âœ… ä»»åŠ¡å®Œæˆ! ä»£ç†èŠ‚ç‚¹: {stats['proxies_count']}, è§„åˆ™: {stats['rules_count']}"
    )
    logger.info(
        f"ğŸ“ é…ç½®æ–‡ä»¶: {'clash' + version_file_suffix + '-{your-token}' + '.yaml'}"
    )
    if ida.local_mode:
        logger.info(f"ğŸ“ è¾“å‡ºè·¯å¾„: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    merger_gen_config()


if __name__ == "__main__":
    main()
